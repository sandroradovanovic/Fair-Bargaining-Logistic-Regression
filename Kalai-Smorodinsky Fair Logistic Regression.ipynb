{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y, y_hat):\n",
    "    n1 = np.sum(y == 1)\n",
    "    n2 = np.sum(y == 0)\n",
    "    \n",
    "    R1 = np.sum(stats.rankdata(y_hat.values)[y.values == 1])\n",
    "    \n",
    "    U = R1 - (n1*(n1+1))/2\n",
    "    \n",
    "    return(U/(n1*n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparate_impact(y_hat, s):\n",
    "    priv = np.mean(y_hat.values[s.values == 0])/np.mean(y_hat.values[s.values == 1])\n",
    "    disc = np.mean(y_hat.values[s.values == 1])/np.mean(y_hat.values[s.values == 0])\n",
    "    \n",
    "    return np.min([priv, disc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_of_opportunity(y_hat, y, s, out = 1):\n",
    "    eoo = np.mean(y_hat.values[(s.values == 1) & (y.values == out)]) / np.mean(y_hat.values[(s.values == 0) & (y.values == out)])\n",
    "    \n",
    "    return(eoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w, X):\n",
    "    return(1/(1 + np.exp(-np.sum(w*X, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(w, X, y):\n",
    "    y_hat = sigmoid(w, X).values\n",
    "    \n",
    "    # NUMERICAL UNDERFLOW AND OVERFLOW\n",
    "    y_hat[y_hat == 0] = 0.00001\n",
    "    y_hat[y_hat == 1] = 0.99999\n",
    "    \n",
    "    return -np.mean(y.values * np.log2(y_hat) + (1 - y.values) * np.log2(1 - y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_score(w, X, y, s):\n",
    "    X_d = X.loc[s == 1, :]\n",
    "    X_p = X.loc[s == 0, :]\n",
    "    \n",
    "    y_d = y[s == 1]\n",
    "    y_p = y[s == 0]\n",
    "    \n",
    "    y_hat = sigmoid(w, X)\n",
    "    y_d_hat = sigmoid(w, X_d)\n",
    "    y_p_hat = sigmoid(w, X_p)\n",
    "    \n",
    "    print(f'AUC: {auc(y, y_hat)}, AUC Disc: {auc(y_d, y_d_hat)}, AUC Priv: {auc(y_p, y_p_hat)}')\n",
    "    print(f'LL: {logistic_loss(w, X, y)}, LL Disc: {logistic_loss(w, X_d, y_d)}, LL Priv: {logistic_loss(w, X_p, y_p)}')\n",
    "    print(f'Disparate impact {disparate_impact(y_hat, s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalai Smorodinsky Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KS_fair_solution:\n",
    "    \n",
    "    def __init__(self, normalize=True):\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # ----- HELP FUNCTIONS -----\n",
    "    def _logistic_loss(self, y, y_hat):\n",
    "        '''\n",
    "        Calculate Logistic Loss\n",
    "        \n",
    "        Parameters:\n",
    "        y : numpy.array\n",
    "            Vector of true values of the outcome\n",
    "        y_hat : numpy.array\n",
    "            Vector of predicted values of the outcome\n",
    "            \n",
    "        Returns:\n",
    "        score : ndarray\n",
    "            Logistic Loss\n",
    "        '''\n",
    "        \n",
    "        return -np.mean(y.values * np.log2(y_hat.values) + (1 - y.values) * np.log2(1 - y_hat.values))\n",
    "    \n",
    "    def _disparate_impact(self, y_hat, s):\n",
    "        '''\n",
    "        Calculate Disparate Impact\n",
    "        \n",
    "        Parameters:\n",
    "        y_hat : numpy.array\n",
    "            Vector of predicted values of the outcome\n",
    "            \n",
    "        Returns:\n",
    "        score : ndarray\n",
    "            Disparate Impact\n",
    "        '''\n",
    "        \n",
    "        priv = np.mean(y_hat.values[s.values == 0])/np.mean(y_hat.values[s.values == 1])\n",
    "        disc = np.mean(y_hat.values[s.values == 1])/np.mean(y_hat.values[s.values == 0])\n",
    "\n",
    "        return np.min([priv, disc])\n",
    "    \n",
    "    def _sigmoid(self, X):\n",
    "        return(1/(1 + np.exp(-np.sum(self.w * X, axis=1))))\n",
    "    \n",
    "    # ----- OPERATIONS -----\n",
    "    def _prepare_ks(self):\n",
    "        '''\n",
    "        Calculate DataFrame where each attribute is represented as a row, \n",
    "        with columns representing Disparate Impact and Logistic Loss. \n",
    "        As a result this method will create a new DataFrame in an instance \n",
    "        of this class with rows representing attributes and columns representing\n",
    "        Disparate Impact, Logistic Loss and their ratio for Discriminated and\n",
    "        Privileged groups\n",
    "        '''\n",
    "        \n",
    "        values = []\n",
    "\n",
    "        for el in range(X.shape[1]):\n",
    "            w_d_zero = np.repeat(0.0, self.X.shape[1])\n",
    "            w_p_zero = np.repeat(0.0, self.X.shape[1])\n",
    "\n",
    "            w_d_zero[el] = self.w_d[el].copy()\n",
    "            w_p_zero[el] = self.w_p[el].copy()\n",
    "\n",
    "            y_d_hat = sigmoid(w_d_zero, X)\n",
    "            y_p_hat = sigmoid(w_p_zero, X)\n",
    "\n",
    "            di_d = self._disparate_impact(y_d_hat, s)\n",
    "            di_p = self._disparate_impact(y_p_hat, s)\n",
    "\n",
    "            ll_d = self._logistic_loss(y, y_d_hat)\n",
    "            ll_p = self._logistic_loss(y, y_p_hat)\n",
    "\n",
    "            values.append([X.columns[el], w_d[el], di_d, ll_d, w_p[el], di_p, ll_p])\n",
    "    \n",
    "        ks_bargaining = pd.DataFrame(values, columns=['Attribute', 'Coef_D', 'DI_D', 'LL_D', 'Coef_P', 'DI_P', 'LL_P'])\n",
    "        ks_bargaining['DI_LL_D'] = ks_bargaining['DI_D']/ks_bargaining['LL_D']\n",
    "        ks_bargaining['DI_LL_P'] = ks_bargaining['DI_P']/ks_bargaining['LL_P']\n",
    "    \n",
    "        ks_bargaining = ks_bargaining.set_index('Attribute')\n",
    "        \n",
    "        self.ks_dataset = ks_bargaining\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def _calculate(self):\n",
    "        ks_data = self.ks_dataset.copy()\n",
    "    \n",
    "        # IF NORMALIZATION IS NEEDED\n",
    "        if self.normalize:\n",
    "            ks_data = ks_data[['DI_LL_D', 'DI_LL_P']].T.apply(lambda x: x - min(x), axis=1)\n",
    "        else:\n",
    "            ks_data = ks_data[['DI_LL_D', 'DI_LL_P']].T\n",
    "    \n",
    "        # MULTIPLY VALUE WITH MAX FROM OTHER ROW\n",
    "        ks_data = ks_data * np.flip(np.max(ks_data, axis=1)).values[:, np.newaxis]\n",
    "\n",
    "        # OPTIMIZATION VECTOR PREPARATION (MAX_2 * ROW_1 - MAX_1 * ROW_2)\n",
    "        ks_opt_data = ks_data.iloc[0, :] - ks_data.iloc[1, :]\n",
    "\n",
    "        # OPTIMIZATION\n",
    "        def goal_fun_ks(w_ks, ks_data):\n",
    "            return -np.sum(ks_data * w_ks)\n",
    "\n",
    "        def const_w_ks(w_ks):\n",
    "            return np.sum(w_ks) - 1\n",
    "\n",
    "        def ks_optimize(ks_data):\n",
    "            w_ks = np.repeat(0.0, ks_data.shape[0])\n",
    "\n",
    "            cons = ({'type': 'eq', 'fun': const_w_ks})\n",
    "            bounds = [(0, 1) for n in w_ks]\n",
    "            \n",
    "            np.random.seed(seed=2021)\n",
    "            model = optimize.minimize(fun=goal_fun_ks, x0=w_ks, args=(ks_data), \n",
    "                                      method='SLSQP', constraints=cons, bounds=bounds)\n",
    "\n",
    "            return model\n",
    "\n",
    "        self.optimization = ks_optimize(ks_opt_data)\n",
    "        return\n",
    "    \n",
    "    def _final_weights(self):\n",
    "        w_ks = self.w_d * self.optimization.x + self.w_p * (1 - self.optimization.x)\n",
    "        self.w = w_ks\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # ----- FIT AND PREDICT -----\n",
    "    def fit(self, w_d, w_p, X, y, s):\n",
    "        '''\n",
    "        Calculate Kalai-Smorodinsky Fair Logistic Regression solution\n",
    "\n",
    "        Parameters:\n",
    "        w_d : numpy.array\n",
    "            Vector of logistic regression coefficients for discriminated group\n",
    "        w_p : numpy.array\n",
    "            Vector of logistic regression coefficients for privileged group\n",
    "        X : pandas.DataFrame\n",
    "            Matrix of input attributes\n",
    "        y : pandas.Series\n",
    "            Output attribute vector (label)\n",
    "        s : pandas.Series\n",
    "            Sensitive attribute vector\n",
    "            \n",
    "        Returns:\n",
    "        KSFairLR : self\n",
    "            Object of Kalai Smorodinsky Fair Logistic Regression\n",
    "        '''\n",
    "    \n",
    "        # SAVE TO CLASS\n",
    "        self.w_d = w_d\n",
    "        self.w_p = w_p\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.s = s\n",
    "        \n",
    "        # PERFORM IN ORDER\n",
    "        self._prepare_ks()\n",
    "        self._calculate()\n",
    "        self._final_weights()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Perform predictions\n",
    "        \n",
    "        Parameters:\n",
    "        X : pandas.DataFrame\n",
    "            DataFrame for which predicitons should be created\n",
    "            \n",
    "        Returns:\n",
    "        score : ndarray\n",
    "            Probabilities of the outcome\n",
    "        '''\n",
    "        \n",
    "        return _sigmoid(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/adult_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Income']\n",
    "s = data['Sex']\n",
    "\n",
    "X = data.drop(['Income', 'Sex'], axis=1)\n",
    "X = (X - np.mean(X))/np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d = X.loc[s == 1, :]\n",
    "X_p = X.loc[s == 0, :]\n",
    "\n",
    "y_d = y[s == 1]\n",
    "y_p = y[s == 0]\n",
    "\n",
    "w = np.repeat(0.0, X.shape[1])\n",
    "\n",
    "np.random.seed(seed=2021)\n",
    "w_d = optimize.minimize(fun=logistic_loss, x0=w, args=(X_d, y_d), method='SLSQP').x\n",
    "\n",
    "np.random.seed(seed=2021)\n",
    "w_p = optimize.minimize(fun=logistic_loss, x0=w, args=(X_p, y_p), method='SLSQP').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00979595,  0.36193893,  0.05885222,  6.21990438,  0.25698949,\n",
       "        0.45681634, -0.07728854,  0.08679764,  0.00304607,  0.13773888,\n",
       "       -0.06817859, -0.13079843, -0.17905286, -0.08963746,  0.22324022,\n",
       "        0.10568674, -0.55310772,  0.9963871 , -0.50521498, -0.29795124,\n",
       "       -0.10585004, -0.35619919,  0.62527459,  0.63950295,  0.06747036,\n",
       "        0.03012814,  0.12239981, -0.22580896, -0.35939612, -0.20071742,\n",
       "       -0.02153195,  0.18657878, -0.16904293, -0.0642122 ,  0.40223403,\n",
       "       -0.02507333,  0.02047668, -0.12699095, -0.0174208 ,  0.11061625,\n",
       "       -0.04406924,  0.06588862, -0.05125516])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02381715,  0.19689868,  0.02431283,  6.1106116 ,  0.26765291,\n",
       "        0.23885482, -0.03481642,  0.06697494,  0.03999298, -0.05262586,\n",
       "       -0.03610741, -0.07745785, -0.28070703, -0.072653  ,  0.23400059,\n",
       "        0.09651818, -0.10385168,  0.3179215 , -0.37565187,  0.20953251,\n",
       "       -0.06172431,  0.06721985, -0.01944622, -0.18117273,  0.19076702,\n",
       "       -0.22816248, -0.21320206, -0.18291017, -0.14658905,  1.60688179,\n",
       "        0.2114016 , -0.00113102,  0.01209145,  0.06266838, -0.15361467,\n",
       "       -0.07775242, -0.01541034, -0.00038542, -0.04108725, -0.0253009 ,\n",
       "       -0.06237742,  0.00617068, -0.03008206])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.841676546482703, AUC Disc: 0.9099177749906092, AUC Priv: 0.7887198656722318\n",
      "LL: 0.9203350532539918, LL Disc: 0.36132870217616464, LL Priv: 1.1966571004067812\n",
      "Disparate impact 0.3003921311331426\n"
     ]
    }
   ],
   "source": [
    "performance_score(w_d, X, y, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8584174949202784, AUC Disc: 0.8589295681091325, AUC Priv: 0.8566341362274587\n",
      "LL: 0.7850611801547899, LL Disc: 0.993621940289187, LL Priv: 0.6819676534265845\n",
      "Disparate impact 0.7979329555236878\n"
     ]
    }
   ],
   "source": [
    "performance_score(w_p, X, y, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KS_fair_solution at 0x1979c124208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = KS_fair_solution()\n",
    "\n",
    "new_model.fit(w_d, w_p, X, y, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: -0.03720750321064222\n",
       "     jac: array([-0.00317593, -0.00160082, -0.00310886,  0.        , -0.0029984 ,\n",
       "       -0.00378368, -0.00314565, -0.00289143, -0.00428216, -0.00490541,\n",
       "       -0.00311956, -0.0032656 , -0.00120816, -0.00284798,  0.        ,\n",
       "       -0.0031453 ,  0.00763289,  0.01289409, -0.00432301, -0.01284302,\n",
       "       -0.00323486,  0.00168116,  0.        ,  0.00658117, -0.00021333,\n",
       "       -0.00968664, -0.00540319, -0.00354004, -0.00193376, -0.0372075 ,\n",
       "        0.00045363, -0.00137302, -0.00191114, -0.00302979, -0.00049779,\n",
       "       -0.00333289, -0.00321337, -0.00168957, -0.00319203, -0.00337384,\n",
       "       -0.0030111 , -0.00315156, -0.003197  ])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 495\n",
       "     nit: 11\n",
       "    njev: 11\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02381715,  0.19689868,  0.02431283,  6.1106116 ,  0.26765291,\n",
       "        0.23885482, -0.03481642,  0.06697494,  0.03999298, -0.05262586,\n",
       "       -0.03610741, -0.07745785, -0.28070703, -0.072653  ,  0.23400059,\n",
       "        0.09651818, -0.10385168,  0.3179215 , -0.37565187,  0.20953251,\n",
       "       -0.06172431,  0.06721985, -0.01944622, -0.18117273,  0.19076702,\n",
       "       -0.22816248, -0.21320206, -0.18291017, -0.14658905, -0.20071742,\n",
       "        0.2114016 , -0.00113102,  0.01209145,  0.06266838, -0.15361467,\n",
       "       -0.07775242, -0.01541034, -0.00038542, -0.04108725, -0.0253009 ,\n",
       "       -0.06237742,  0.00617068, -0.03008206])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8642381666115667, AUC Disc: 0.8731113219172607, AUC Priv: 0.857148500116131\n",
      "LL: 0.6614496094419803, LL Disc: 0.6106858702764913, LL Priv: 0.6865425986366328\n",
      "Disparate impact 0.7760250242271908\n"
     ]
    }
   ],
   "source": [
    "performance_score(new_model.w, X, y, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
