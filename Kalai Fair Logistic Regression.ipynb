{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y, y_hat):\n",
    "    n1 = np.sum(y == 1)\n",
    "    n2 = np.sum(y == 0)\n",
    "    \n",
    "    R1 = np.sum(stats.rankdata(y_hat.values)[y.values == 1])\n",
    "    \n",
    "    U = R1 - (n1*(n1+1))/2\n",
    "    \n",
    "    return(U/(n1*n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparate_impact(y_hat, s):\n",
    "    priv = np.mean(y_hat.values[s.values == 0])/np.mean(y_hat.values[s.values == 1])\n",
    "    disc = np.mean(y_hat.values[s.values == 1])/np.mean(y_hat.values[s.values == 0])\n",
    "    \n",
    "    return np.min([priv, disc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_of_opportunity(y_hat, y, s, out = 1):\n",
    "    eoo = np.mean(y_hat.values[(s.values == 1) & (y.values == out)]) / np.mean(y_hat.values[(s.values == 0) & (y.values == out)])\n",
    "    \n",
    "    return(eoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w, X):\n",
    "    return(1/(1 + np.exp(-np.sum(w[:-1] * X, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalai Fair Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalai_fair_logistic_regression(w, X, y, s):\n",
    "    '''\n",
    "    Kalai Bargaining solution applied to Logistic Regression.\n",
    "    Instead of optimizing logistic loss, one needs to optimize negative value of the new variable \n",
    "    subject to logistic losses of two groups (discriminated and privileged) having a greater value of that variable\n",
    "    \n",
    "    Paramters:\n",
    "    w : ndarray\n",
    "        Coefficients of the logistic regression with an additional variable\n",
    "    X : pandas.DataFrame\n",
    "        DataFrame of input attributes\n",
    "    y : ndarray\n",
    "        Outcome vector\n",
    "    s : ndarray\n",
    "        Sensitive attribute vector\n",
    "    '''\n",
    "    \n",
    "    return w[-1]\n",
    "\n",
    "def constraint_logistic_loss(w, X, y, s):\n",
    "    '''\n",
    "    Logistic losses for both discriminated and privileged groups. \n",
    "    Due to constraint types in scipy (<= 0), max is transfered to min with negative values of logistic losses\n",
    "    \n",
    "    Parameters:\n",
    "    w : ndarray\n",
    "        Coefficients of the logistic regression with an additional variable\n",
    "    X : pandas.DataFrame\n",
    "        DataFrame of input attributes\n",
    "    y : ndarray\n",
    "        Outcome vector\n",
    "    s : ndarray\n",
    "        Sensitive attribute vector\n",
    "    '''\n",
    "    \n",
    "    w_coef = w[:-1]\n",
    "    \n",
    "    X_d, X_p = X.loc[s.values == 1, :], X.loc[s.values == 0, :]\n",
    "    y_d, y_p = y[s.values == 1], y[s.values == 0]\n",
    "    \n",
    "    y_d_hat = sigmoid(w, X_d).values\n",
    "    y_p_hat = sigmoid(w, X_p).values\n",
    "    \n",
    "    # NUMERICAL UNDERFLOW AND OVERFLOW\n",
    "    y_d_hat[y_d_hat == 0] = 0.0000001\n",
    "    y_d_hat[y_d_hat == 1] = 0.9999999\n",
    "    \n",
    "    y_p_hat[y_p_hat == 0] = 0.0000001\n",
    "    y_p_hat[y_p_hat == 1] = 0.9999999\n",
    "    \n",
    "    disc_loss = np.mean(y_d * np.log2(y_d_hat) + (1 - y_d) * np.log2(1 - y_d_hat)) + w[-1]\n",
    "    priv_loss = np.mean(y_p * np.log2(y_p_hat) + (1 - y_p) * np.log2(1 - y_p_hat)) + w[-1]\n",
    "    \n",
    "    return [disc_loss, priv_loss]\n",
    "\n",
    "def statistical_parity(w, X, s, parity = 0.8):\n",
    "    '''\n",
    "    Adding statistical parity constraints\n",
    "    \n",
    "    Parameters:\n",
    "    w : ndarray\n",
    "        Coefficients of the logistic regression with an additional variable\n",
    "    X : pandas.DataFrame\n",
    "        DataFrame of input attributes\n",
    "    y : ndarray\n",
    "        Outcome vector\n",
    "    s : ndarray\n",
    "        Sensitive attribute vector\n",
    "    '''\n",
    "    \n",
    "    y_hat = sigmoid(w, X)\n",
    "    \n",
    "    # NUMERICAL UNDERFLOW AND OVERFLOW\n",
    "    y_hat[y_hat == 0] = 0.0000001\n",
    "    y_hat[y_hat == 1] = 0.9999999\n",
    "    \n",
    "    lower_bound = parity * np.mean(y_hat.values[s.values == 1]) - np.mean(y_hat.values[s.values == 0])\n",
    "    upper_bound = np.mean(y_hat.values[s.values == 0]) - 1/parity * np.mean(y_hat.values[s.values == 1])\n",
    "    \n",
    "    return [lower_bound, upper_bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(w, X, y):\n",
    "    y_hat = sigmoid(w, X).values\n",
    "    \n",
    "    # NUMERICAL UNDERFLOW AND OVERFLOW\n",
    "    y_hat[y_hat == 0] = 0.0000001\n",
    "    y_hat[y_hat == 1] = 0.9999999\n",
    "    \n",
    "    return -np.mean(y.values * np.log2(y_hat) + (1 - y.values) * np.log2(1 - y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_score(w, X, y, s):\n",
    "    X_d = X.loc[s == 1, :]\n",
    "    X_p = X.loc[s == 0, :]\n",
    "    \n",
    "    y_d = y[s == 1]\n",
    "    y_p = y[s == 0]\n",
    "    \n",
    "    y_hat = sigmoid(w, X)\n",
    "    y_d_hat = sigmoid(w, X_d)\n",
    "    y_p_hat = sigmoid(w, X_p)\n",
    "    \n",
    "    print(f'AUC: {auc(y, y_hat)}, AUC Disc: {auc(y_d, y_d_hat)}, AUC Priv: {auc(y_p, y_p_hat)}')\n",
    "    print(f'LL: {logistic_loss(w, X, y)}, LL Disc: {logistic_loss(w, X_d, y_d)}, LL Priv: {logistic_loss(w, X_p, y_p)}')\n",
    "    print(f'Disparate impact {disparate_impact(y_hat, s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/adult_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Income']\n",
    "s = data['Sex']\n",
    "\n",
    "X = data.drop(['Income', 'Sex'], axis=1)\n",
    "X = (X - np.mean(X))/np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.repeat(0, repeats = X.shape[1] + 1)\n",
    "# parity = 0.8\n",
    "\n",
    "# cons = ({'type': 'ineq', 'fun': constraint_logistic_loss, 'args': (X, y, s)},\n",
    "#         {'type': 'ineq', 'fun': statistical_parity, 'args': (X, s, parity)})\n",
    "\n",
    "cons = ({'type': 'ineq', 'fun': constraint_logistic_loss, 'args': (X, y, s)})\n",
    "\n",
    "adjustment = optimize.minimize(fun=kalai_fair_logistic_regression, x0=w, constraints=cons, \n",
    "                               args=(X, y, s), method='SLSQP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8585715865158207, AUC Disc: 0.8602453380361497, AUC Priv: 0.8559451342936354\n",
      "LL: 0.6815791431331266, LL Disc: 0.6815790469226015, LL Priv: 0.6815791906908854\n",
      "Disparate impact 0.796601043746812\n"
     ]
    }
   ],
   "source": [
    "performance_score(adjustment.x, X, y, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
