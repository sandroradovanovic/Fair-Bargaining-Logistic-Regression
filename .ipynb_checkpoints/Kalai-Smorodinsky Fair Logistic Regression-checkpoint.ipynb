{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y, y_hat):\n",
    "    n1 = np.sum(y == 1)\n",
    "    n2 = np.sum(y == 0)\n",
    "    \n",
    "    R1 = np.sum(stats.rankdata(y_hat.values)[y.values == 1])\n",
    "    \n",
    "    U = R1 - (n1*(n1+1))/2\n",
    "    \n",
    "    return(U/(n1*n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparate_impact(y_hat, s):\n",
    "    priv = np.mean(y_hat.values[s.values == 0])/np.mean(y_hat.values[s.values == 1])\n",
    "    disc = np.mean(y_hat.values[s.values == 1])/np.mean(y_hat.values[s.values == 0])\n",
    "    \n",
    "    return np.min([priv, disc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_of_opportunity(y_hat, y, s, out = 1):\n",
    "    eoo = np.mean(y_hat.values[(s.values == 1) & (y.values == out)]) / np.mean(y_hat.values[(s.values == 0) & (y.values == out)])\n",
    "    \n",
    "    return(eoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w, X):\n",
    "    return(1/(1 + np.exp(-np.sum(w*X, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(w, X, y):\n",
    "    y_hat = sigmoid(w, X).values\n",
    "    \n",
    "    # NUMERICAL UNDERFLOW AND OVERFLOW\n",
    "    y_hat[y_hat == 0] = 0.0000001\n",
    "    y_hat[y_hat == 1] = 0.9999999\n",
    "    \n",
    "    return -np.mean(y.values * np.log2(y_hat) + (1 - y.values) * np.log2(1 - y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_score(w, X, y, s):\n",
    "    X_d = X.loc[s.values == 1, :]\n",
    "    X_p = X.loc[s.values == 0, :]\n",
    "    \n",
    "    y_d = y[s.values == 1]\n",
    "    y_p = y[s.values == 0]\n",
    "    \n",
    "    y_hat = sigmoid(w, X)\n",
    "    y_d_hat = sigmoid(w, X_d)\n",
    "    y_p_hat = sigmoid(w, X_p)\n",
    "    \n",
    "    print(f'AUC: {auc(y, y_hat)}, AUC Disc: {auc(y_d, y_d_hat)}, AUC Priv: {auc(y_p, y_p_hat)}')\n",
    "    print(f'LL: {logistic_loss(w, X, y)}, LL Disc: {logistic_loss(w, X_d, y_d)}, LL Priv: {logistic_loss(w, X_p, y_p)}')\n",
    "    print(f'Disparate impact {disparate_impact(y_hat, s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalai Smorodinsky Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KS_fair_solution:\n",
    "    \n",
    "    def __init__(self, fair=1, normalize=True):\n",
    "        '''\n",
    "        Construction of KS_fair_solution\n",
    "        \n",
    "        Parameters:\n",
    "        fair : numeric\n",
    "            Importance of the fairness in the final solution\n",
    "        normalize : bool\n",
    "            Normalization of the Disparate Impact Logistic Loss ratio\n",
    "        '''\n",
    "        \n",
    "        self.fair = fair\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # ----- HELP FUNCTIONS -----\n",
    "    def _logistic_loss(self, y, y_hat):\n",
    "        '''\n",
    "        Calculate Logistic Loss\n",
    "        \n",
    "        Parameters:\n",
    "        y : numpy.array\n",
    "            Vector of true values of the outcome\n",
    "        y_hat : numpy.array\n",
    "            Vector of predicted values of the outcome\n",
    "            \n",
    "        Returns:\n",
    "        score : ndarray\n",
    "            Logistic Loss\n",
    "        '''\n",
    "        \n",
    "        return -np.mean(y.values * np.log2(y_hat.values) + (1 - y.values) * np.log2(1 - y_hat.values))\n",
    "    \n",
    "    def _disparate_impact(self, y_hat, s):\n",
    "        '''\n",
    "        Calculate Disparate Impact\n",
    "        \n",
    "        Parameters:\n",
    "        y_hat : numpy.array\n",
    "            Vector of predicted values of the outcome\n",
    "            \n",
    "        Returns:\n",
    "        score : ndarray\n",
    "            Disparate Impact\n",
    "        '''\n",
    "        \n",
    "        priv = np.mean(y_hat.values[s.values == 0])/np.mean(y_hat.values[s.values == 1])\n",
    "        disc = np.mean(y_hat.values[s.values == 1])/np.mean(y_hat.values[s.values == 0])\n",
    "\n",
    "        return np.min([priv, disc])\n",
    "    \n",
    "    def _sigmoid(self, X):\n",
    "        return(1/(1 + np.exp(-np.sum(self.w * X, axis=1))))\n",
    "    \n",
    "    # ----- OPERATIONS -----\n",
    "    def _prepare_ks(self):\n",
    "        '''\n",
    "        Calculate DataFrame where each attribute is represented as a row, \n",
    "        with columns representing Disparate Impact and Logistic Loss. \n",
    "        As a result this method will create a new DataFrame in an instance \n",
    "        of this class with rows representing attributes and columns representing\n",
    "        Disparate Impact, Logistic Loss and their ratio for Discriminated and\n",
    "        Privileged groups\n",
    "        '''\n",
    "        \n",
    "        values = []\n",
    "\n",
    "        for el in range(X.shape[1]):\n",
    "            w_d_zero = np.repeat(0.0, self.X.shape[1])\n",
    "            w_p_zero = np.repeat(0.0, self.X.shape[1])\n",
    "\n",
    "            w_d_zero[el] = self.w_d[el].copy()\n",
    "            w_p_zero[el] = self.w_p[el].copy()\n",
    "\n",
    "            y_d_hat = sigmoid(w_d_zero, X)\n",
    "            y_p_hat = sigmoid(w_p_zero, X)\n",
    "\n",
    "            di_d = self._disparate_impact(y_d_hat, s)\n",
    "            di_p = self._disparate_impact(y_p_hat, s)\n",
    "\n",
    "            ll_d = self._logistic_loss(y, y_d_hat)\n",
    "            ll_p = self._logistic_loss(y, y_p_hat)\n",
    "\n",
    "            values.append([X.columns[el], w_d[el], di_d, ll_d, w_p[el], di_p, ll_p])\n",
    "    \n",
    "        ks_bargaining = pd.DataFrame(values, columns=['Attribute', 'Coef_D', 'DI_D', 'LL_D', 'Coef_P', 'DI_P', 'LL_P'])\n",
    "        \n",
    "        ks_bargaining[['DI_D', 'LL_D', 'DI_P', 'LL_P']] = ks_bargaining[['DI_D', 'LL_D', 'DI_P', 'LL_P']]*1./np.max(ks_bargaining[['DI_D', 'LL_D', 'DI_P', 'LL_P']], axis=0)\n",
    "        \n",
    "        ks_bargaining[['DI_D', 'DI_P']] = self.fair * ks_bargaining[['DI_D', 'DI_P']]\n",
    "        \n",
    "        ks_bargaining['DI_LL_D'] = ks_bargaining['DI_D']/ks_bargaining['LL_D']\n",
    "        ks_bargaining['DI_LL_P'] = ks_bargaining['DI_P']/ks_bargaining['LL_P']\n",
    "    \n",
    "        ks_bargaining = ks_bargaining.set_index('Attribute')\n",
    "        \n",
    "        self.ks_dataset = ks_bargaining\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def _calculate(self):\n",
    "        ks_data = self.ks_dataset.copy()\n",
    "    \n",
    "        # IF NORMALIZATION IS NEEDED\n",
    "        if self.normalize:\n",
    "            ks_data = ks_data[['DI_LL_D', 'DI_LL_P']].T.apply(lambda x: x - min(x), axis=1)\n",
    "        else:\n",
    "            ks_data = ks_data[['DI_LL_D', 'DI_LL_P']].T\n",
    "    \n",
    "        # MULTIPLY VALUE WITH MAX FROM OTHER ROW\n",
    "        ks_data = ks_data * np.flip(np.max(ks_data, axis=1)).values[:, np.newaxis]\n",
    "\n",
    "        # OPTIMIZATION VECTOR PREPARATION (MAX_2 * ROW_1 - MAX_1 * ROW_2)\n",
    "        ks_opt_data = ks_data.iloc[0, :] - ks_data.iloc[1, :]\n",
    "\n",
    "        # OPTIMIZATION\n",
    "        def goal_fun_ks(w_ks, ks_data):\n",
    "            return -np.sum(ks_data * w_ks)\n",
    "\n",
    "        # CONSTRAINT THE INTENSITY OF CHANGES\n",
    "        def const_w_ks(w_ks):\n",
    "            return np.sum(w_ks) - 1\n",
    "\n",
    "        def ks_optimize(ks_data):\n",
    "            w_ks = np.repeat(0.0, ks_data.shape[0])\n",
    "\n",
    "            cons = ({'type': 'eq', 'fun': const_w_ks})\n",
    "            bounds = [(0, 1) for n in w_ks]\n",
    "            \n",
    "            np.random.seed(seed=2021)\n",
    "#             model = optimize.minimize(fun=goal_fun_ks, x0=w_ks, args=(ks_data), \n",
    "#                                       method='SLSQP', constraints=cons, bounds=bounds)\n",
    "\n",
    "            model = optimize.minimize(fun=goal_fun_ks, x0=w_ks, args=(ks_data), \n",
    "                                      method='SLSQP', bounds=bounds)\n",
    "\n",
    "            return model\n",
    "\n",
    "        self.optimization = ks_optimize(ks_opt_data)\n",
    "        return\n",
    "    \n",
    "    def _final_weights(self):\n",
    "        w_ks = self.w_d * self.optimization.x + self.w_p * (1 - self.optimization.x)\n",
    "        self.w = w_ks\n",
    "        \n",
    "        return\n",
    "    \n",
    "    # ----- FIT AND PREDICT -----\n",
    "    def fit(self, w_d, w_p, X, y, s):\n",
    "        '''\n",
    "        Calculate Kalai-Smorodinsky Fair Logistic Regression solution\n",
    "\n",
    "        Parameters:\n",
    "        w_d : numpy.array\n",
    "            Vector of logistic regression coefficients for discriminated group\n",
    "        w_p : numpy.array\n",
    "            Vector of logistic regression coefficients for privileged group\n",
    "        X : pandas.DataFrame\n",
    "            Matrix of input attributes\n",
    "        y : pandas.Series\n",
    "            Output attribute vector (label)\n",
    "        s : pandas.Series\n",
    "            Sensitive attribute vector\n",
    "            \n",
    "        Returns:\n",
    "        KSFairLR : self\n",
    "            Object of Kalai Smorodinsky Fair Logistic Regression\n",
    "        '''\n",
    "    \n",
    "        # SAVE TO CLASS\n",
    "        self.w_d = w_d\n",
    "        self.w_p = w_p\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.s = s\n",
    "        \n",
    "        # PERFORM IN ORDER\n",
    "        self._prepare_ks()\n",
    "        self._calculate()\n",
    "        self._final_weights()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Perform predictions\n",
    "        \n",
    "        Parameters:\n",
    "        X : pandas.DataFrame\n",
    "            DataFrame for which predicitons should be created\n",
    "            \n",
    "        Returns:\n",
    "        score : ndarray\n",
    "            Probabilities of the outcome\n",
    "        '''\n",
    "        \n",
    "        return _sigmoid(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/adult_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Income']\n",
    "s = data['Sex']\n",
    "\n",
    "X = data.drop(['Unnamed: 0', 'Income', 'Sex'], axis=1)\n",
    "X = (X - np.mean(X))/np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d = X.loc[s == 1, :]\n",
    "X_p = X.loc[s == 0, :]\n",
    "\n",
    "y_d = y[s == 1]\n",
    "y_p = y[s == 0]\n",
    "\n",
    "w = np.repeat(0.0, X.shape[1])\n",
    "\n",
    "np.random.seed(seed=2021)\n",
    "w_d = optimize.minimize(fun=logistic_loss, x0=w, args=(X_d, y_d), method='SLSQP').x\n",
    "\n",
    "np.random.seed(seed=2021)\n",
    "w_p = optimize.minimize(fun=logistic_loss, x0=w, args=(X_p, y_p), method='SLSQP').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_score(w_d, X, y, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_score(w_p, X, y, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = KS_fair_solution(fair=0.15)\n",
    "\n",
    "new_model.fit(w_d, w_p, X, y, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_score(new_model.w, X, y, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
